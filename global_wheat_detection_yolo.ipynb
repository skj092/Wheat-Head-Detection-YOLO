{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "global-wheat-detection-yolo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/XUnEAXCykqybK/rNYsyr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Wheat-Head-Detection-YOLO/blob/main/global_wheat_detection_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Wheat Detection using YOLO"
      ],
      "metadata": {
        "id": "McjhtzCclm-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the repository"
      ],
      "metadata": {
        "id": "bOclumIAlqr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/skj092/Global-Wheat-Detection-YOLO.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEqA7tF1WuBc",
        "outputId": "fcac3e45-feb9-4af8-b669-ab184b64075f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Global-Wheat-Detection-YOLO'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 44 (delta 19), reused 5 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Global-Wheat-Detection-YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzY5Ow46WwqN",
        "outputId": "5d61490a-cfae-45e9-a5d8-fc5c19a372f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Global-Wheat-Detection-YOLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning the yolov5 repository"
      ],
      "metadata": {
        "id": "odVkp3csluap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecy1xgx9aXnu",
        "outputId": "e1279e7c-93bd-4000-f518-9655ce02030f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14424, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 14424 (delta 15), reused 25 (delta 9), pack-reused 14379\u001b[K\n",
            "Receiving objects: 100% (14424/14424), 13.41 MiB | 6.60 MiB/s, done.\n",
            "Resolving deltas: 100% (9965/9965), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settin up Directory structure for the YOLO"
      ],
      "metadata": {
        "id": "cn6pM1lqlzM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "mkdir data\n",
        "mkdir data/input\n",
        "mkdir data/preprocessed\n",
        "mkdir data/preprocessed/images\n",
        "mkdir data/preprocessed/labels\n",
        "mkdir data/preprocessed/images/train\n",
        "mkdir data/preprocessed/images/validation\n",
        "mkdir data/preprocessed/labels/train\n",
        "mkdir data/preprocessed/labels/validation"
      ],
      "metadata": {
        "id": "LTa5qSw5XZwr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading dataset using kaggle api"
      ],
      "metadata": {
        "id": "wXh9lvZ_l4d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "file = files.upload()"
      ],
      "metadata": {
        "id": "ls9ImsMLkDvf",
        "outputId": "f665d031-2a26-46c8-fbf5-88281ec86cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-74b202be-ea72-4542-a2da-f139459c6796\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-74b202be-ea72-4542-a2da-f139459c6796\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ../../root/.kaggle/"
      ],
      "metadata": {
        "id": "BUxax-tdkN4A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ../../root/.kaggle"
      ],
      "metadata": {
        "id": "66mPtK1fkNSk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd data/input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4ZJlVy2YmHy",
        "outputId": "ef066f5e-7e02-480d-dab7-d06a4426c222"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Global-Wheat-Detection-YOLO/data/input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c global-wheat-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z7hFyiMYoDQ",
        "outputId": "144ce514-355e-47b7-a156-d5049d3afb56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading global-wheat-detection.zip to /content/Global-Wheat-Detection-YOLO/data/input\n",
            " 95% 577M/607M [00:15<00:01, 22.0MB/s]\n",
            "100% 607M/607M [00:16<00:00, 39.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q global-wheat-detection.zip"
      ],
      "metadata": {
        "id": "4NiOosUgY0D3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Global-Wheat-Detection-YOLO/"
      ],
      "metadata": {
        "id": "G2RV_MOOkemW",
        "outputId": "0795fa61-861e-4758-bf93-61f13394116b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Global-Wheat-Detection-YOLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python munge_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5auIng1Y3oH",
        "outputId": "698d9efd-f786-4c27-befe-090e2771991a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3035/3035 [00:02<00:00, 1036.48it/s]\n",
            "100% 338/338 [00:00<00:00, 916.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing training setup"
      ],
      "metadata": {
        "id": "fToBrHVdl9rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYLbnZvZCVT",
        "outputId": "3a940397-9033-46fc-87c0-bf3010490393"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Global-Wheat-Detection-YOLO/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch wheat.yaml"
      ],
      "metadata": {
        "id": "OELoJbmHk3MH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train: ../data/preprocessed/images/train\n",
        "# val: ../data/preprocessed/images/validation\n",
        "# nc: 1\n",
        "# names: [\"wheat\"]"
      ],
      "metadata": {
        "id": "IE2Pr4epk3u_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 512 --batch 16  --epochs 5 --data wheat.yaml "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJY3IlaeZJUe",
        "outputId": "fa66bddc-3560-48b4-fd0d-a74a23e74e10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=wheat.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"ipython\" \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (7.9.0)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from thop>=0.1.1) (1.12.1+cu113)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->thop>=0.1.1) (4.1.1)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.1 thop-0.1.1.post2209072238\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /content/Global-Wheat-Detection-YOLO/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 üöÄ v6.2-211-g32a9218 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 164MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 305MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/Global-Wheat-Detection-YOLO/data/preprocessed/labels/train' images and labels...3035 found, 0 missing, 0 empty, 0 corrupt: 100% 3035/3035 [00:01<00:00, 1765.07it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Global-Wheat-Detection-YOLO/data/preprocessed/labels/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/Global-Wheat-Detection-YOLO/data/preprocessed/labels/validation' images and labels...338 found, 0 missing, 0 empty, 0 corrupt: 100% 338/338 [00:00<00:00, 699.48it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Global-Wheat-Detection-YOLO/data/preprocessed/labels/validation.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.80 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      2.38G    0.09814     0.2491          0        578        512: 100% 190/190 [03:42<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:11<00:00,  1.05s/it]\n",
            "                   all        338      15129      0.386      0.554      0.403      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      2.98G     0.0652     0.2447          0        566        512: 100% 190/190 [03:40<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:09<00:00,  1.18it/s]\n",
            "                   all        338      15129      0.605      0.718      0.681      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      2.98G    0.05909     0.2405          0        723        512: 100% 190/190 [03:38<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:08<00:00,  1.25it/s]\n",
            "                   all        338      15129      0.863      0.819      0.877      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      2.98G    0.05338      0.235          0        537        512: 100% 190/190 [03:37<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:08<00:00,  1.31it/s]\n",
            "                   all        338      15129      0.897      0.839      0.903      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      2.98G    0.05108     0.2322          0        671        512: 100% 190/190 [03:39<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:08<00:00,  1.34it/s]\n",
            "                   all        338      15129       0.89      0.843      0.902      0.432\n",
            "\n",
            "5 epochs completed in 0.319 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 11/11 [00:18<00:00,  1.67s/it]\n",
            "                   all        338      15129      0.896      0.839      0.903      0.443\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After restart runtime"
      ],
      "metadata": {
        "id": "j2Cw2qn0mDQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cd Global-Wheat-Detection-YOLO/"
      ],
      "metadata": {
        "id": "dqzqt80lZRBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd yolov5"
      ],
      "metadata": {
        "id": "SZyibPKJbgVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python train.py --img 1024 --batch 16  --epochs 20 --data wheat.yaml "
      ],
      "metadata": {
        "id": "UlKBzlY0lSfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "dAP_Jy2Bc547"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/Global-Wheat-Detection-YOLO/yolov5/runs/train/exp/weights/best.pt ."
      ],
      "metadata": {
        "id": "TsvlX48geI2L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = \"/content/Global-Wheat-Detection-YOLO/data/input/test\""
      ],
      "metadata": {
        "id": "Lzm5SYXH3Cer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/Global-Wheat-Detection-YOLO/data/input/test --weights best.pt --img 512 --conf 0.1 --save-txt --save-conf --exist-ok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN0Df0Ykc8N8",
        "outputId": "7120c7b5-cb2e-40d4-f8f0-c329330a445a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['best.pt'], source=/content/Global-Wheat-Detection-YOLO/data/input/test, data=data/coco128.yaml, imgsz=[512, 512], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v6.2-211-g32a9218 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/10 /content/Global-Wheat-Detection-YOLO/data/input/test/2fd875eaa.jpg: 512x512 34 wheats, 9.9ms\n",
            "image 2/10 /content/Global-Wheat-Detection-YOLO/data/input/test/348a992bb.jpg: 512x512 40 wheats, 9.1ms\n",
            "image 3/10 /content/Global-Wheat-Detection-YOLO/data/input/test/51b3e36ab.jpg: 512x512 40 wheats, 9.0ms\n",
            "image 4/10 /content/Global-Wheat-Detection-YOLO/data/input/test/51f1be19e.jpg: 512x512 48 wheats, 9.0ms\n",
            "image 5/10 /content/Global-Wheat-Detection-YOLO/data/input/test/53f253011.jpg: 512x512 36 wheats, 9.5ms\n",
            "image 6/10 /content/Global-Wheat-Detection-YOLO/data/input/test/796707dd7.jpg: 512x512 26 wheats, 9.1ms\n",
            "image 7/10 /content/Global-Wheat-Detection-YOLO/data/input/test/aac893a91.jpg: 512x512 33 wheats, 9.1ms\n",
            "image 8/10 /content/Global-Wheat-Detection-YOLO/data/input/test/cb8d261a3.jpg: 512x512 40 wheats, 11.0ms\n",
            "image 9/10 /content/Global-Wheat-Detection-YOLO/data/input/test/cc3532ff6.jpg: 512x512 30 wheats, 9.2ms\n",
            "image 10/10 /content/Global-Wheat-Detection-YOLO/data/input/test/f5a1f0358.jpg: 512x512 38 wheats, 9.0ms\n",
            "Speed: 0.5ms pre-process, 9.4ms inference, 1.2ms NMS per image at shape (1, 3, 512, 512)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "10 labels saved to runs/detect/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Global-Wheat-Detection-YOLO/yolov5/runs/detect/exp/labels"
      ],
      "metadata": {
        "id": "KViIMIMv3vaQ",
        "outputId": "6faba3da-8f2e-4531-f5ff-d25fcff81bd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2fd875eaa.txt  51b3e36ab.txt  53f253011.txt  aac893a91.txt  cc3532ff6.txt\n",
            "348a992bb.txt  51f1be19e.txt  796707dd7.txt  cb8d261a3.txt  f5a1f0358.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "rqPdtC8LeDf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import pandas as pd "
      ],
      "metadata": {
        "id": "WEmubCYp4C9e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(s):\n",
        "    x = int(1024 * (s[1] - s[3]/2))\n",
        "    y = int(1024 * (s[2] - s[4]/2))\n",
        "    w = int(1024 * s[3])\n",
        "    h = int(1024 * s[4])\n",
        "    \n",
        "    return(str(s[5]) + ' ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h))"
      ],
      "metadata": {
        "id": "BgZ7dLjBnhjY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Global-Wheat-Detection-YOLO/data/input/sample_submission.csv', 'w') as myfile:\n",
        "\n",
        "    # prepare submission\n",
        "    wfolder = '/content/Global-Wheat-Detection-YOLO/yolov5/runs/detect/exp/labels/'\n",
        "    for f in os.listdir(wfolder):\n",
        "        fname = wfolder + f\n",
        "        xdat = pd.read_csv(fname, sep = ' ', header = None)\n",
        "        outline = f[:-4] + ' ' + ' '.join(list(xdat.apply(lambda s: convert(s), axis = 1)))\n",
        "        myfile.write(outline + '\\n')\n",
        "        \n",
        "myfile.close()    "
      ],
      "metadata": {
        "id": "siMjJ62kno5K"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/Global-Wheat-Detection-YOLO/data/input/sample_submission.csv"
      ],
      "metadata": {
        "id": "3nTBmhUanu-r",
        "outputId": "fadabd6d-3f31-4e41-e053-f53248cefdc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51b3e36ab 0.101184 622 366 177 89 0.110753 609 786 275 129 0.118652 795 639 168 151 0.119321 972 437 49 103 0.126129 6 0 91 106 0.130337 991 752 33 186 0.177592 354 420 126 147 0.208632 504 393 115 83 0.240929 878 188 142 149 0.243724 908 616 110 120 0.246489 902 124 73 81 0.26302 5 314 67 135 0.337515 971 699 51 108 0.449617 0 713 38 91 0.456082 0 344 49 119 0.458403 102 655 103 75 0.464367 861 709 78 81 0.495461 7 436 83 250 0.528045 382 424 103 81 0.569905 0 0 96 220 0.600069 3 594 86 140 0.600823 691 617 259 122 0.602465 679 812 302 120 0.617597 490 356 327 129 0.685519 330 438 92 183 0.704962 614 767 156 97 0.712602 499 178 103 86 0.713334 411 927 94 94 0.720016 816 440 208 167 0.735532 476 581 81 75 0.736771 871 286 152 138 0.75589 105 844 158 81 0.756305 528 22 252 138 0.757429 872 186 135 78 0.762657 235 643 89 152 0.768415 449 314 145 103 0.782458 361 154 106 89 0.789298 468 14 76 138 0.795367 3 817 100 99 0.817732 0 907 84 112\n",
            "cc3532ff6 0.13366 4 352 120 113 0.152811 989 221 33 133 0.248026 0 192 25 73 0.393342 723 725 145 92 0.442669 988 280 35 97 0.462092 726 745 78 70 0.501871 412 222 84 81 0.591816 6 478 64 73 0.593619 20 347 106 65 0.608575 0 761 38 88 0.649703 284 839 99 78 0.664987 310 292 78 72 0.665079 29 655 76 68 0.672956 784 691 104 117 0.697856 959 2 60 83 0.75691 482 400 108 147 0.758173 556 828 124 174 0.761201 79 813 126 161 0.763082 768 7 103 129 0.769011 269 641 86 156 0.770172 693 471 138 81 0.772642 564 302 108 102 0.776334 100 608 80 138 0.780029 3 410 142 96 0.78038 716 298 117 89 0.783965 614 429 78 92 0.789095 910 131 113 78 0.801372 382 0 70 99 0.806266 774 823 161 163 0.823746 492 568 88 133\n",
            "f5a1f0358 0.105651 1 118 22 68 0.112392 418 680 73 76 0.120233 116 545 86 115 0.140819 405 736 96 136 0.141636 49 822 89 80 0.144433 125 621 68 62 0.147211 950 429 67 80 0.181735 473 301 80 108 0.195803 789 587 81 80 0.19582 129 538 81 70 0.270434 411 806 94 72 0.276352 298 572 75 73 0.497041 7 5 57 56 0.555947 528 3 102 92 0.575152 457 576 65 64 0.586629 398 687 91 129 0.594336 475 804 129 83 0.60151 96 824 51 51 0.628299 319 465 126 86 0.629962 261 660 92 73 0.635376 235 560 73 96 0.646043 448 299 99 183 0.653891 759 588 102 128 0.662259 953 442 65 167 0.664082 3 841 54 99 0.669049 68 461 140 115 0.675978 702 570 62 106 0.695262 154 240 72 92 0.717842 601 728 99 78 0.721469 413 173 60 62 0.724574 808 408 108 86 0.728139 556 398 64 88 0.731574 672 109 78 86 0.735085 887 637 84 147 0.735831 543 279 103 103 0.764037 142 754 152 119 0.776238 210 309 129 99 0.807524 686 200 113 89\n",
            "aac893a91 0.108967 484 4 147 43 0.132677 634 1 113 76 0.138214 28 448 86 92 0.161474 813 4 142 38 0.179084 846 0 145 22 0.185201 659 1 103 44 0.192059 558 523 103 122 0.223632 994 611 27 89 0.226743 797 983 91 38 0.24235 863 3 154 32 0.255099 297 852 102 91 0.300187 335 908 65 49 0.313137 481 980 81 44 0.492809 359 255 140 177 0.495345 826 621 84 144 0.510991 175 577 112 160 0.549756 820 664 97 241 0.657187 234 841 149 88 0.660864 588 776 99 120 0.664648 94 614 117 86 0.676373 562 69 133 192 0.710483 568 529 115 199 0.711858 298 0 78 64 0.731489 74 0 89 161 0.73377 63 857 119 62 0.734291 462 854 70 92 0.739274 739 767 78 115 0.741512 32 448 106 161 0.74186 337 659 110 152 0.760453 618 913 70 108 0.768393 243 85 135 145 0.787017 356 522 94 86 0.795474 697 382 115 184\n",
            "cb8d261a3 0.100174 994 477 30 108 0.100423 0 865 32 103 0.113572 912 443 65 65 0.14227 886 980 92 44 0.153104 739 443 38 51 0.159041 842 403 52 67 0.166051 533 2 60 51 0.187573 506 926 145 88 0.223698 408 896 86 49 0.225793 655 868 68 76 0.242323 987 886 33 65 0.277248 482 499 136 73 0.280605 397 297 112 51 0.298168 828 866 54 49 0.307962 991 339 30 97 0.341949 950 266 68 57 0.354068 882 404 49 76 0.426243 420 784 44 46 0.47446 770 991 73 33 0.576395 574 825 103 88 0.688917 757 492 103 78 0.727973 0 795 38 80 0.733957 592 39 73 81 0.740909 461 816 72 73 0.742437 907 168 91 126 0.761173 169 909 83 76 0.76805 601 245 67 126 0.769091 34 561 165 96 0.769912 804 217 59 108 0.771869 533 527 99 46 0.773648 21 864 76 140 0.778015 697 112 62 165 0.77829 445 460 104 103 0.78226 264 779 112 65 0.793062 521 273 76 128 0.797904 761 713 70 80 0.801375 847 154 54 120 0.808639 435 120 110 67 0.812987 314 155 99 218 0.878127 646 683 99 62\n",
            "348a992bb 0.108058 944 580 67 140 0.152505 482 837 70 70 0.192231 2 425 83 124 0.200693 425 502 122 126 0.303054 0 508 60 78 0.36776 688 39 78 78 0.45821 10 415 60 65 0.515799 466 538 81 81 0.52123 435 970 73 52 0.523369 51 268 68 73 0.532995 467 961 156 60 0.569839 0 217 44 83 0.572738 502 715 97 70 0.59335 891 984 70 40 0.621331 140 602 70 57 0.623045 662 53 97 94 0.655503 747 987 115 36 0.679517 725 478 67 70 0.691879 408 499 86 103 0.699954 373 857 99 112 0.701936 550 744 92 89 0.718996 856 843 75 73 0.719624 1 936 59 86 0.724845 383 213 76 81 0.726304 919 560 83 94 0.729707 1 469 133 94 0.732786 98 207 94 81 0.735665 668 387 102 84 0.737557 109 926 94 70 0.737643 969 672 54 73 0.743873 306 164 81 100 0.752799 142 35 110 86 0.762257 934 785 86 78 0.772251 767 109 115 97 0.774586 542 30 73 97 0.778073 283 336 80 83 0.785902 596 442 126 92 0.786173 3 321 112 86 0.787248 453 653 73 76 0.826253 743 219 124 83\n",
            "796707dd7 0.127144 671 686 97 145 0.15079 2 760 28 106 0.159102 437 197 67 78 0.186049 693 64 89 75 0.277306 735 992 108 28 0.316044 839 560 83 92 0.36316 236 0 117 41 0.405383 87 555 181 86 0.419694 388 631 86 115 0.495358 297 288 84 119 0.530765 465 272 110 84 0.537685 245 320 99 222 0.541999 691 711 57 103 0.558459 354 1 81 48 0.579758 225 836 113 68 0.605691 675 563 117 156 0.632172 623 41 73 67 0.63547 678 451 100 120 0.640587 98 800 102 76 0.644744 196 475 133 100 0.665889 67 89 131 106 0.679468 939 74 83 92 0.738508 511 789 83 92 0.740678 0 451 62 70 0.749193 712 834 103 83 0.827388 894 335 113 81\n",
            "53f253011 0.102838 981 469 41 113 0.11729 767 986 163 35 0.125835 198 511 89 83 0.156754 666 341 174 152 0.172528 672 323 62 103 0.208911 492 572 142 113 0.233954 638 320 96 176 0.343737 0 755 113 70 0.436245 993 499 28 103 0.50556 130 627 102 113 0.515542 403 267 131 94 0.548866 519 398 88 76 0.622374 736 376 145 120 0.668498 195 535 113 122 0.684424 579 575 75 138 0.717195 356 344 158 89 0.723657 471 457 138 197 0.728223 294 608 129 99 0.728363 296 438 177 86 0.728616 925 809 97 204 0.732221 603 333 97 183 0.740506 0 396 94 124 0.742795 615 686 92 142 0.748857 152 96 80 92 0.754792 452 166 115 122 0.757526 910 740 70 86 0.761664 390 826 100 113 0.763315 231 838 110 92 0.764811 21 594 122 136 0.765667 619 103 120 138 0.769665 308 62 86 126 0.791997 931 194 92 133 0.793595 138 917 113 106 0.793865 149 317 142 103 0.794663 780 629 113 106 0.838024 18 36 138 94\n",
            "2fd875eaa 0.107082 206 995 96 28 0.110768 987 447 36 97 0.121593 128 989 86 33 0.158987 2 811 24 41 0.260336 325 990 84 32 0.336292 0 813 38 54 0.378446 148 999 80 20 0.436635 997 484 25 76 0.458997 0 257 35 100 0.499731 242 1001 65 19 0.561101 99 1 120 48 0.690214 427 969 115 54 0.694987 989 579 33 89 0.717647 436 476 56 70 0.717889 727 149 91 89 0.721157 110 30 103 78 0.72759 787 725 97 75 0.74586 124 843 73 65 0.746895 479 7 65 78 0.747039 422 62 115 78 0.755952 227 0 96 54 0.782816 0 0 104 70 0.788129 463 492 76 142 0.800035 0 905 104 83 0.80193 735 886 89 86 0.803453 535 865 103 113 0.803543 892 51 99 84 0.803784 3 737 81 100 0.818749 935 773 73 81 0.822514 392 793 75 81 0.825556 465 347 120 102 0.827168 109 580 133 80 0.831281 941 646 83 92 0.831563 912 885 62 88\n",
            "51f1be19e 0.101132 1001 423 22 102 0.103984 330 299 57 73 0.1047 578 888 54 54 0.105204 78 704 99 144 0.105637 638 408 83 68 0.106562 425 173 59 86 0.111335 995 525 28 94 0.11886 868 96 62 62 0.131327 997 376 25 110 0.136894 854 264 115 110 0.139646 841 990 88 30 0.14294 562 607 100 103 0.153442 733 743 73 49 0.154802 767 637 86 41 0.162943 0 800 19 73 0.164729 783 21 76 65 0.177192 556 1002 88 19 0.184766 482 2 73 22 0.188283 331 177 86 131 0.192946 398 361 38 59 0.198632 5 201 57 54 0.199543 660 438 76 44 0.203705 613 481 92 65 0.204512 368 127 73 100 0.232258 8 0 62 59 0.238455 852 371 104 92 0.254177 390 212 65 97 0.271952 1002 519 22 62 0.283244 102 65 44 57 0.297584 449 57 54 70 0.313893 360 146 103 165 0.330944 524 984 110 38 0.362547 573 583 176 113 0.477537 208 942 88 78 0.495834 844 285 131 165 0.540702 657 582 103 89 0.546716 649 792 97 75 0.558407 30 0 84 67 0.570181 687 921 89 83 0.576102 876 658 135 94 0.597636 247 122 113 103 0.605844 291 475 110 104 0.644343 2 377 44 104 0.649055 819 90 103 70 0.686304 614 90 142 170 0.710161 769 877 149 104 0.712035 505 480 190 92 0.719237 800 765 115 91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N-8Yp0QIn1c6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}